---
title: 'First python spider'
date: 2019-07-16 12:27:14
tags: [python,çˆ¬è™«,å£çº¸,ç¼–ç¨‹,NSFW]
published: true
hideInList: false
feature: https://www.z4a.net/images/2019/07/16/2018-07-13-005825.jpg
---
çˆ¬å–wallhavenå£çº¸ç½‘ç«™NSFWèµ„æºğŸ˜

<!-- more -->


åˆšåˆšå¼€å§‹å­¦ä¹  python å†™äº†ä¸€ä¸ªå°çˆ¬è™«æ¥çˆ¬å– è±†ç“£å¤±è´¥äº†,äºæ˜¯è½¬è€Œçˆ¬å– [wallhaven](https://wallhaven.cc/) å®ƒæ‹¥æœ‰å¤§é‡çš„è¶…æ¸…å£çº¸èµ„æº å¹¶ä¸”åªè¦æ³¨å†Œå°±å¯ä»¥å¼€å¯ NSFW é€‰é¡¹ æµè§ˆ,ä¸‹è½½çš†æ— é™åˆ¶.

é¦–å…ˆ å¦‚æœä½ åªæƒ³çˆ¬å–æ™®é€šçš„èµ„æº å°±å¯ä»¥ä¸æ³¨å†Œ ä¹Ÿä¸ä½¿ç”¨ cookies .å°†ä¸‹é¢çš„ç¨‹åºå°æ”¹å°±å¯ä»¥åšåˆ°.ä½†æ˜¯åœ¨æ­¤åªä»‹ç»å¦‚ä½•çˆ¬å–åŒ…å«NSFWçš„èµ„æº.

1. é¦–å…ˆæ³¨å†Œç½‘ç«™ ç™»å½•

2. ![1.png](https://www.z4a.net/images/2019/07/16/1.png)åœ¨ lastest é¡µé¢ä¸­é€‰æ‹© NSFW é€‰é¡¹ (è“è‰²ç®­å¤´)å¹¶ç‚¹å‡»åˆ·æ–°æŒ‰é’®(çº¢è‰²ç®­å¤´)

3. ![2c6289b60c5340c40.png](https://www.z4a.net/images/2019/07/16/2c6289b60c5340c40.png)

   åœ¨é¡µé¢ä¸­ æŒ‰f12è°ƒå‡º network åˆ·æ–°é¡µé¢(æµè§ˆå™¨çš„åˆ·æ–° åŒºåˆ«äºç¬¬äºŒæ­¥) é€‰æ‹©ç¬¬ä¸€ä¸ª æ‰¾åˆ° Request Headers é‡Œçš„ cookie å…¨éƒ¨å¤åˆ¶

4. å°†ç¬¬ä¸‰æ­¥å¤åˆ¶çš„ cookie é»è´´åˆ° ä¸‹é¢ä»£ç å—ä¸­çš„  cookies_text = 'ä½ è‡ªå·±çš„' æ›¿æ¢'ä½ è‡ªå·±çš„'  filepath é€‰æ‹©ä¸€ä¸ªä½ æƒ³æ”¾çš„åœ°æ–¹ ç„¶åè¿è¡Œå°±å¥½äº† æ¨èç›´æ¥å¤åˆ¶åˆ° pychramé‡Œé¢è¿è¡Œ

```python
from bs4 import BeautifulSoup
import requests
cookie = {}
def get_cookies():
    cookies_text = 'ä½ è‡ªå·±çš„'
    for each in cookies_text.split(';'):
        name,value = each.strip().split('=',1)
        cookie[name] = value
def downimg(url):
    filepath = 'E:\File\Tmp\ ' #è‡ªå·±å†™
    r = requests.get(url, stream=True)
    if r.status_code != 200:
        return
    with open(filepath[:-1]+url[-10:], 'wb') as code:
        for img_data in r.iter_content(128):
            code.write(img_data)


def realimg(url):
    web_data = requests.get(url,cookies=cookie)
    Soup = BeautifulSoup(web_data.text, 'lxml')
    imgs = Soup.select('#wallpaper')
    for img in imgs:
        downimg(img.get('src'))

def start(num):
    url = 'https://wallhaven.cc/search?categories=111&purity=111&sorting=date_added&order=desc&page='+num
    web_data = requests.get(url,cookies=cookie)
    Soup = BeautifulSoup(web_data.text, 'lxml')
    img_web_links = Soup.select('#thumbs > section > ul > li > figure > a.preview')
    for img_web in img_web_links:
        realimg(img_web.get('href'))


get_cookies()
for i in range(1,26514):
    start(str(i))
```

ğŸ˜‚ç©çš„å¼€å¿ƒ