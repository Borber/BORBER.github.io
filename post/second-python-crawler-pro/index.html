
<!DOCTYPE html>
<html lang="zh-CN">
<head>
 <meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Second python crawler pro | BORBER</title>	
</style>
<link rel="stylesheet" href="https://borber.github.io/styles/main.css">
<script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<script type='text/javascript' src='https://borber.github.io/media/scripts/script.js'></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-142130514-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-142130514-1');
</script>

<style type="text/css">
header {
    text-align: center;
    padding: 120px 0px 40px 0px;
    background: #515865 center no-repeat;
    font-size: 16px;
    color: #fff;
    background-size: cover;
    background-image:url(
			https://www.z4a.net/images/2019/07/23/Jade-Wallpaper.jpg
			);
}
		</style>

 	
</head>
<body class="post-template-default single single-post postid-70 single-format-standard">
    <div id="wrapper">
        
			
		<header id="header ddq" class="site-header" 
		
		style="background-image:url(https://www.z4a.net/images/2019/07/18/1.jpg)"
		
		>
			<div class="site-branding">
									<h1 class="site-title"><a href="https://borber.github.io" rel="home">BORBER</a></h1>
										
					<h2 class="site-description">世俗为枷锁 世人皆自缚</h2>
										
							</div>
			<nav id="nav-wrapper">
				<div class="container">
					<div class="nav-toggle">
						<div class="bars">
							<div class="bar"></div>
							<div class="bar"></div>
							<div class="bar"></div>
						</div>
					</div><!-- /nav-toggle -->
					<div class="clear"></div>
					<ul id="" class="vtmenu">
		 
     			
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-12">
	 
	<a  href="/"> 首页</a></li>
	
    
     			
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-12">
	 
	<a  href="/archives"> 归档</a></li>
	
    
     			
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-12">
	 
	<a  href="/tags"> 标签</a></li>
	
    
     			
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-12">
	 
	<a  href="/post/about"> 关于</a></li>
	
    
     			
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-12">
	 
	<a  href="https://borber.github.io/friend/"> 友链</a></li>
	
    

</ul>
</li>		
		
</ul>				</div>
			</nav><!-- #navigation -->
						<div class="jingge">

			
<a  href="/atom.xml" target="_blank" ><i class="iconfont icon-rss"></i></a>
 
    

    
			
<a  href="https://github.com/Borber" target="_blank" ><i class="iconfont icon-github"></i></a>
 
    

    

    

    

    

    

    

    

    

    
        </header><!-- #masthead -->

		<div id="content" class="container">
			<div class="row">
	<div class="col-md-8 site-main">
				
<article id="post-70" class="post-70 post type-post status-publish format-standard hentry category-5 tag-10 tag-9 tag-11">

	
	                      
		<div class="entry-content">
			<h1 class="entry-title">Second python crawler pro</h1>
<div class="entry-meta">
	
	           <a href="https://borber.github.io/post/second-python-crawler-pro">
							 <i class="iconfont icon-rili"> 
							</i> 2019-07-18</a> 
			
</span>
													 
		</div>
                  
			<div class="entry-summary">
				<p><p>爬取<a href="http://www.zerobyw4.com/">zero搬运网</a> 漫画 有福利哦 🤪 Pro</p>
<!-- more -->
<pre><code>	写完第二个爬虫之后,写了好几个,但是总归是因为技术原因,达不到自己想要的效果,在重写第二个爬虫时这种感觉尤为强烈,所以写完这个之后,回去继续看剩下的网课,充实自己

	 因为不会反爬以及多线程 , 以及模拟登录 等等一系列的技术,所以写的非常简陋,但是还是用上了 MongoDB 因为涉及到数据库的操作 所以不是简单复制下来就能跑,需要安装相应的 包,以及软件,但现在比较懒,所以省略,如果有朋友遇见困难,可以评论区留言,我会回复,或者更新的.
</code></pre>
<ol>
<li>爬取全站版本 是我一开始写的,但是由于数据太大,需要长时间的访问,不可避免地导致反爬机制,以及链接断开之后,没有重连手段,导致十分鸡肋,所以产生更改目标,重写爬取单部漫画方案.</li>
<li>在全站版本上修改的单部版本,但没想到是大改,所以,单部版本更加优秀 可以 参考单部 修改全站版本 还是本人太懒 不想改了.</li>
</ol>
<pre><code class="language-python">from bs4 import BeautifulSoup
import requests
import os
import time
import pymongo

client = pymongo.MongoClient('localhost',27017)
Mongo_zero = client['zero']
Mongo_urls = Mongo_zero['urls']
Mongo_detials = Mongo_zero['detials']
Mongo_img_links = Mongo_zero['img_links']

header = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3833.0 Safari/537.36',
    'Cookie':'你自己的'

}

web_head = 'http://www.zerobyw4.com'
rootpath = 'E:\File\Tmp\ ' #自己改
seq = '\ '
filend = '.jpg'

def mkdir(path):
    folder = os.path.exists(path)

    if not folder:  # 判断是否存在文件夹如果不存在则创建为文件夹
        os.makedirs(path)  # makedirs 创建文件时如果路径不存在会创建这个路径
        print
        &quot;---  new folder...  ---&quot;
        print
        &quot;---  OK  ---&quot;

    else:
        print
        &quot;---  There is this folder!  ---&quot;



def start():
    count = 0
    for NUM in range(1,46):
        url = 'http://www.zerobyw4.com/plugin.php?id=jameson_manhua&amp;c=index&amp;a=ku&amp;&amp;page=' +str(NUM)
        web_data = requests.get(url)
        Soup = BeautifulSoup(web_data.text, 'lxml')
        urls = Soup.select('div.uk-card &gt; div &gt; a')
        titles = Soup.select('p.uk-text-truncate &gt; a')
        for url,title in zip(urls,titles):
            data = {
                'index':count,
                'title':title.get_text(),
                'url':web_head+url.get('href')[1:]
            }
            count += 1
            print(data)
            mkdir(rootpath[:-1]+seq[0]+data['title'])
            Mongo_urls.insert_one(data)
        time.sleep(2)

def one():
    for item in Mongo_urls.find():
        web_data = requests.get(item['url'])
        Soup = BeautifulSoup(web_data.text, 'lxml')
        details = Soup.select('a.uk-button-default')
        for count,each in enumerate(details):
            data = {
                'index':item['index'],
                'count':count,
                'url':web_head + each.get('href')[1:]
            }
            print(data)
            mkdir(rootpath[:-1]+seq[0]+item['title']+seq[0]+str(data['count']))
            Mongo_detials.insert_one(data)
        time.sleep(2)


def realimg():
    num = 0
    for item in Mongo_detials.find():
        web_data = requests.get(item['url'], headers=header)
        Soup = BeautifulSoup(web_data.text, 'lxml')
        imgs = Soup.select('div.mb0 &gt; img')
        NUM = 0
        for img in imgs:
            data = {
                'num':num,
                'title':Mongo_urls.find({'index':item['index']})[0]['title'],
                'chapter':item['count'],
                'count':NUM,
                'url':img.get('src')
            }
            NUM = NUM + 1
            print(data)
            Mongo_img_links.insert_one(data)
        time.sleep(2)



def downimg():
    for item in Mongo_img_links.find():
        filename = rootpath[:-1] + seq[0] + item['title'] + seq[0] + str(item['chapter']) + seq[0] + str(item['count']) + filend
        if os.path.exists(filename):
            continue
        r = requests.get(item['url'], stream=True)
        if r.status_code != 200:
            return
        with open(filename, 'wb') as code:
            for img_data in r.iter_content(128):
                code.write(img_data)
        r.close()
        time.sleep(1)

start()
one()
realimg()
downimg()

</code></pre>
<ol start="2">
<li>爬取单部漫画</li>
</ol>
<pre><code class="language-python">from bs4 import BeautifulSoup
import requests
import os
import pymongo

client = pymongo.MongoClient('localhost', 27017)
Mongo_zero = client['zero']
Mongo_Details = Mongo_zero['details']
Mongo_img_links = Mongo_zero['img_links']

header = {
    'User-Agent': '',  # yours
    'Cookie': ''  # yours

}

web_head = 'http://www.zerobyw4.com'
rootpath = '/home/x/BORBER/BORBER/File/Tmp'  # yours
seq = '/'


def mkdir(path):
    folder = os.path.exists(path)
    if not folder:
        os.makedirs(path)


def one(url_x, rootpath_s):
    web_data = requests.get(url_x, headers=header)
    soup = BeautifulSoup(web_data.text, 'lxml')
    details = soup.select('a.uk-button-default')
    title = soup.select('li &gt; h3.uk-heading-line')[0].get_text()
    rootpath_x = rootpath_s + seq[0] + title
    mkdir(rootpath_x)
    for index, each in enumerate(details):
        data = {
            'chapter': index,
            'title': each.get_text(),
            'url': web_head + each.get('href')[1:]
        }
        mkdir(rootpath_x + seq[0] + data['title'])
        print(data)
        Mongo_Details.insert_one(data)
    return rootpath_x


def realimg():
    num = 0
    for item in Mongo_Details.find():
        web_data = requests.get(item['url'], headers=header)
        soup = BeautifulSoup(web_data.text, 'lxml')
        imgs = soup.select('div.mb0 &gt; img')
        count = 0
        for img in imgs:
            data = {
                'num': num,
                'chapter': item['chapter'],
                'count': count,
                'url': img.get('src')
            }
            num += 1
            count += 1
            print(data)
            Mongo_img_links.insert_one(data)


def downimg(rootpath_x):
    for item in Mongo_img_links.find():
        filename = rootpath_x + seq[0] + Mongo_Details.find({'chapter': item['chapter']})[0]['title'] + seq[0] + str(item['count']) + item['url'][-4:]
        print(filename)
        # if os.path.exists(filename):
        #     continue
        r = requests.get(item['url'], headers=header, stream=True)
        with open(filename, 'wb') as code:
            for img_data in r.iter_content(128):
                code.write(img_data)


Mongo_zero.drop_collection('details')
Mongo_zero.drop_collection('img_links')
print('输入你想下载的漫画详情页网址:')
url = input()
rootpath = one(url, rootpath)
realimg()
downimg(rootpath)

</code></pre>
<p>漫画哪有 python有趣 嘿嘿嘿 😃</p>
</p>
							</div>
	<div class="vt-post-tags">
 
				<a href="https://borber.github.io/tag/zzy4LPH8S" rel="tag">python</a>	
				 
				<a href="https://borber.github.io/tag/C-16BRfGV" rel="tag">爬虫</a>	
				 
				<a href="https://borber.github.io/tag/mR79ZebU2" rel="tag">编程</a>	
				 
				<a href="https://borber.github.io/tag/qlm952wiz" rel="tag">NSFW</a>	
				 
					</div>						
<nav class="navigation3 post-navigation3" role="navigation">
		
		<div class="nav-links3">
      
		 
		<div class="nav-next3"><a href="https://borber.github.io/post/third-python-reptile" rel="next"> Third python crawler</a></div>
		
		</div>
	</nav>
		</div>
		
 
		
</article>

<div id="marlin_lite_about_widget-2" class="widget marlin_lite_about_widget">
			<h4 class="widget-title">评论</h4>	

			 
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: '46faa605211a1eadeb3a',
    clientSecret: 'ac6abe30a4d9f21248acb00499811e3d0537f849',
    repo: 'gitment-comments',
    owner: 'Borber',
    admin: ['Borber'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          
          
        
   
  
 

		</div>

			</div>
			


<div class="col l3 hide-on-med-and-down">
	
        <div class="toc-widget">
			
            <div class="toc-title"></div>
			
            <div id="toc-content">
			
			
			</div>
        </div>
    </div>


<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.5.0/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '.entry-summary',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('.entry-summary').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });
    });
</script>										 

 
       


			</div>
		</div>

		
		 	<footer id="colophon" class="site-footer">

			<div class="container">
	
				<div class="copyright">Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a><br>Theme:   <a href="https://github.com/alterfang/gridea-theme-pan" target="_blank" title="Pan"><span>Pan</span></a>. Powered by <a href="https://gridea.dev/" target="_blank" title="Gridea"><span>Gridea</span></a></div>		
			</div><!-- .container -->
		
		</footer><!-- #colophon -->

</div>

<script src="https://cdn.bootcss.com/fitvids/1.2.0/jquery.fitvids.min.js"></script>
<script type='text/javascript' src='https://borber.github.io/media/scripts/marlin-scripts.js'></script>

		<script data-no-instant>
    (function ($) {
        $.extend({
            adamsOverload: function () {
                $('.navigation:eq(0)').remove();
                $("").attr("rel" , "external");
                $("a[rel='external'],a[rel='external nofollow']").attr("target","_blank");
                $("a.vi").attr("rel" , "");
                $.viewImage({
                    'target'  : 'img',
                    'exclude' : '.vsmile-icons img,.gallery img',
                    'delay'   : 300
                });
                $.lately({
                    'target' : '.commentmetadata a,.infos time,.post-list time'
                });
                prettyPrint();
                
                $('ul.links li a').each(function(){
                    if($(this).parent().find('.bg').length==0){
                        $(this).parent().append('<!---<div class="bg" style="background-image:url(https://c3.glgoo.top/s2/favicons?domain='+$(this).attr("href")+')"></div>--->')
                    }
                });
            }
        });
    })(jQuery);
    jQuery.adamsOverload();
</script>

</body>
</html>
